# Deep Learning CheatSheet

The following summary is inspired by: [https://www.globalsqa.com/deep-learning-cheat-sheet/](Deep Learning CheatSheet)

## 1. Introduction

Deep Learning is a subset of machine learning that uses artificial neural networks (Current state of the art) to solve problems. The two main benefits are:

1. Automatic feature extraction: Unlike traditional machine learning techniques (Input -> Feature Extraction -> Algorithm -> Output), it removes the need of manual feature extraction/engineering.
2. Non-Linearity: Non linearity is easily 


There are several kinds of architechtures, all based on the concept of the perceptron:


The main concepts related to artificial neural networks are the following:

## 2. Training Neural Networks

### 2.1 Main Training Algorithm

### 2.2 Regularization

### 2.3 Tips

### 2.4 Transfer learning

#### 2.4.1 Fine-tuning

#### 2.4.2 Feature extraction

### 2.5 Multi-task Learning


## 2. Activation Functions

## 3. Loss Functions

## 4. Optimizer algorithms

## 5. Evaluation Metrics

## 6. Architectures

### 6.1 Feed-Forward Neural Network (FNN or MLP)


### 6.2 Recurrent Neural Network (RNN) 

### 6.2.1 Recurrent Unit (RNN)

### 6.2.2 Gated Recurrent Unit (GRU)

### 6.2.3 Long-Short Term Memory Unit (LTSM) 


### 6.3 Convolutional networks 

#### 6.3.1 Convolutional Neural Network (CNN)

#### 6.3.2 Capsule Networks (CapsNets)




### 6.4 Generative Networks

#### 6.4.1 Auto Encoders (AE)

#### 6.4.2 Variational Auto Encoders (VAE)

#### 6.4.3 Generative Adversarial Networks (GAN)

#### 6.4.4 Difusion Model 

#### 6.4.5 Deep Belief Networks



### 6.5 Transformers

#### 6.5.1 Attention

#### 6.5.2 Transformer


### 6.6 Graph Models

#### 6.6.1 Graph Neural Networks (GNN)

#### 6.6.2 Graph Convolutional Networks (GCN)

#### 6.6.3 Graph Attention Networks (GAT)




### 6.7 Hybrid Models 

#### 6.7.1 Neural Architecture Search (NAS)

#### 6.7.2 Memory augmented neural networks (MANN)

#### 6.7.3 Neural Ordinary Differential Equations (ODE)

#### 6.7.4 Multi-modal Models



### 6.8 Reinforcement Models

#### 6.8.1 Deep-Q Networks (DQN)

#### 6.8.2 Actor Critic 


### 6.9 Self-Organizing Maps

### 6.10 Self Supervised Learning


 
## 7. Other important Deep Learning Concepts

### 7.1 Few-Shot and Zero-Shot

### 7.2 Mixture of Experts (MoE)

### 7.3 Retrieval Augmented Generation (RAG)



## 8. Explainability and Interpretability

### 8.1 SHAP 

### 8.2 LIME

### 8.3 Attention VIZ




## 9 Deep Learning Hardware & Compilatin

### 9.1 Hardware

### 9.2 Compilation

### 9.3 Compression



